<!DOCTYPE html>
<html lang="zh-cn">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="format-detection" content="email=no" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="format-detection" content="telephone=no" />
    <meta name="renderer" content="webkit">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Amaze UI" />
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />
    <title>Fanxuan Liu CV </title>
    <link rel="shortcut icon" href="assets/images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet"  type="text/css" href="assets/css/typo.css">
    <link rel="stylesheet" type="text/css" href="assets/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="assets/css/index.css">

    <script>
        function loading() {
            document.getElementsByClassName('avatar')[0].style.display = 'block';
            document.getElementsByClassName('loading')[0].style.display = 'none';
        }
    </script>
</head>

<body>

    <header class="header"></header>

    <article class="container">
        <section class="side" id="side">


            <label class="switch" style="display: none;" onchange="switchFixed()">
                <script type="text/javaScript">
                    function switchFixed() {
                    var value = document.getElementById('side').style.position === 'fixed' ? 'absolute' : 'fixed';
                    document.getElementById('side').style.position = value;
                }
            </script>
                <input id="cb" type="checkbox">
                <span class="slider round"></span>
            </label>
            <style>
                @media (min-width: 414px) {
                    .switch {
                        position: relative;
                        display: inline-block !important;
                        width: 60px;
                        height: 34px;
                    }

                    .switch input {
                        display: none;
                    }

                    .slider {
                        position: absolute;
                        cursor: pointer;
                        top: 0;
                        left: 0;
                        right: 0;
                        bottom: 0;
                        background-color: #ccc;
                        -webkit-transition: .4s;
                        transition: .4s;
                    }

                    .slider:before {
                        position: absolute;
                        content: "";
                        height: 26px;
                        width: 26px;
                        left: 4px;
                        bottom: 4px;
                        background-color: white;
                        -webkit-transition: .4s;
                        transition: .4s;
                    }

                    input:checked+.slider {
                        background-color: #1abc9c;
                    }

                    input:focus+.slider {
                        box-shadow: 0 0 1px #1abc9c;
                    }

                    input:checked+.slider:before {
                        -webkit-transform: translateX(26px);
                        -ms-transform: translateX(26px);
                        transform: translateX(26px);
                    }

                    .slider.round {
                        border-radius: 34px;
                    }

                    .slider.round:before {
                        border-radius: 50%;
                    }
                }
            </style>
            <!-- 左侧固定开关，记得及时删除这段代码 End-->

            <!-- 个人肖像 -->
            <section class="me">
                <section class="portrait">
                    <!-- <div class="loading">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div> -->
                    <!-- 头像照片 -->
                    <img class="avatar" src="assets/images/pic5.jpg">
                </section>

                <h1 class="name"><strong><font size="5">Fanxuan Liu</font></strong></h1>

            </section>


            <!-- 联系方式 -->
            <section class="contact info-unit">
                <h2>
                    <i class="fa fa-user" aria-hidden="true"></i>Contract</h2>
                <hr />
                <ul>
                    <li>
                        <label><i class="fa fa-phone" aria-hidden="true"></i></label>
                        <a>+46 0724445298</a>
                    </li>
                    <li>
                        <label><i class="fa fa-envelope" aria-hidden="true"></i></label>
                        <a href="fanxuan@kth.se">fanxuan@kth.sen</a>
                    </li>
                </ul>
            </section>
            
                <!-- 个人荣誉 -->
                <section class="edu info-unit">
                    <h2>
                        <i class="fa fa-graduation-cap" aria-hidden="true"></i>Grants and Awards</h2>
                    <hr />
    
                    1、 2023 <b>Research Grant,</b> for researchers working with children's diseases and develop care. Stiftelsen Frimurare Barnhuset In Stockholm, Sweden
                    <br />
                    2、 2020 <b>Outstanding Student Cadres,</b> for excellent performance as Head of New Media Department. HUST, China
                    <br />
                    3、 2019 <b>School-level Scholarship,</b> for Hong Kong Academic Exchange program, GPA top 15%. HUST, China
                    <br />
    
                </section>
            <!-- 语言 -->
             <section class="edu info-unit">
                <h2>
                    <i class="fa fa-file-text-o" aria-hidden="true"></i>Language</h2>
                <hr/>
                <ul>
                    <li>
                        <b>English:</b>
                        <br />Completed a two-year programme taught entirely in English.
                        <br />IELTS 7

                    </li>
                    <li>
                        <b>Chinese:</b>
                        <br />Mother Tongue
                    </li>
                </ul>
            </section>
        </section>

        <section class="main">
            
            <!-- 教育 -->

            <section class="project info-unit">
                <h2>
                    <i class="fa fa-graduation-cap" aria-hidden="true"></i>Education</h2>
                <hr />
                <ul>
                    <li>
                        <h3>
                            <span>KTH Royal Institute of Technology</span>
                            <time>2021.9 - 2023.11</time>
                        </h3>
                        <p>
                                MSc in Information and Network Engineering
                        </p>
                        <ul class="info-content">
                            <li>
                                <b>GPA:</b> 4.63/5.00
                            </li>
                            <li>
                                <b>Relevant Coursework:</b> Signal Theory (A), Image and Video Processing (A), Image Analysis and Computer Vision (A), Analysis and Search of Visual Data (A), Project in Multimedia Processing and Analysis (A)
                            </li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span>Huazhong University of Science and Technology (985 and 211 Project, "Double First-Class")</span>
                            <time>2018.9 - 2022.6</time>
                        </h3>
                        <p>
                           BSc in Biomedical Engineering
                        </p>
                        <ul class="info-content">
                            <li>
                                <b>GPA:</b> 3.84/4.00
                            </li>
                            <li>
                                <b>Relevant Coursework:</b> Physics (I) (95/100), Algorithm Design and Analysis (93/100), Principles of Medical Imaging Systems (96/100), Probability Theory and Mathematical Statistics (97/100)
                            </li>
                        </ul>
                    </li>
                </ul>
            </section>


            <!-- 论文经历 -->
            <section class="project info-unit">
                <h2>
                    <i class="fa fa-file-text-o" aria-hidden="true"></i>Publication</h2>
                <hr />
                
                <ul>
                    <li>
                        <h3>
                            <span>A deep learning method for the recovery of standard-dose imaging quality from ultra-low-dose PET on wavelet domain</span>
                            <time>Under Review</time>
                        </h3>
                        <p>Medical Image Analysis (MedIA)</p>
                        <ul class="info-content">
                            <li><b>Fanxuan Liu</b>*, Song Xue*, Hanzhong Wang*, Hong Zhu, Hasan Sari, Marco Viscione, Raphael Sznitman, Rui Guo, Axel Rominger, Biao Li, Kuangyu Shi</li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span>Low-dose PET Image Quality Recovery Benchmar</span>
                            <span class="link">
                                <a href="https://ultra-low-dose-pet.grand-challenge.org/Description/" target="_blank">Link</a>
                            </span>
                            <time>Under Review</time>
                        </h3>
                        <p>IEEE Transactions on Radiation and Plasma Medical Sciences (TRPMS)</p>
                        <ul class="info-content">
                            <li>
                                Song Xue, <b>Fanxuan Liu</b>, Hanzhong Wang, Marco Viscione, Rui Guo, Axel Rominger, Biao Li, Kuangyu Shi
                            </li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span><a href="https://pubmed.ncbi.nlm.nih.gov/36438480/" target="_blank"> Intravital molecular imaging reveals that ROS-caspase-3-GSDME-induced cell punching enhances humoral immunotherapy targeting intracellular tumor antigens</a></span>
                        </h3>
                        <p>Theranostics 2022; 12(17):7603-7623.</p>
                        <ul class="info-content">
                            <li>Bolei Dai, Ren Zhang, Shuhong Qi, Lei Liu, Xian Zhang, Deqiang Deng, Jie Zhang, Yilun Xu, <b>Fanxuan Liu</b>, Zheng Liu, Qingming Luo, Zhihong Zhang</li>                           
                        </ul>
                    </li>
                </ul>
            </section>


            <!-- 项目经验 -->
            <section class="project info-unit">
                <h2>
                    <i class="fa fa-terminal" aria-hidden="true"></i>Research Experience</h2>
                <hr />
                <ul>
                    <li>
                        <h3>
                            <span>Reconstruction of High Quality PET Images by Computational Algorithm</span>
                            <time>2022.7 - 2023.9</time>
                        </h3>
                        <p>University & Supervisor: University of Bern, Kuangyu Shi</p>
                        <ul class="info-content">
                            <li>
                                <i class="fa fa-paper-plane-o" aria-hidden="true"></i>
                                <b>Purpose:</b> Recover high-quality PET (Positron Emission Tomography) images from low statistics corresponding to low dose scans.
                            </li>
                            <li>
                                <i class="fa fa-file-text-o" aria-hidden="true"></i>
                                <b>Contribution:</b><br />
                                <p>
                                    1. Transformed the reconstruction process into wavelet domain: Learned wavelet coefficients through deep learning networks.<br />
                                    2. Proposed a novel network - WaveNet: Introduced 3D-DWT to Unet model for downsampling and adjusted the network layers accordingly.<br />
                               </p>     

                            </li>
                            <li>
                                <i class="fa fa-bars" aria-hidden="true"></i>
                                <b>Result & Benefit:</b> Saved detailed textures and avoided the information loss caused by the pooling layers. Improved the global metrics (NRMSE, PNSR, SSIM) and organ special metrics significantly.
                                
                            </li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span>Video Analysis of Infant Spontaneous Movements</span>
                            <time>2023.3 - 2023.11</time>
                        </h3>
                        <p>University & Supervisor: KTH Royal Institute of Technology, Hedvig Kjellström</p>
                        <ul class="info-content">
                            <li>
                                <i class="fa fa-paper-plane-o" aria-hidden="true"></i>
                                <b>Purpose:</b> Identify infant developmental disorders from 2D infant spontaneous movement videos.
                            </li>
                            <li>
                                <i class="fa fa-file-text-o" aria-hidden="true"></i>
                                <b>Contribution:</b><br />
                                <p>
                                    1. Extracted infant action sequences with Openpose from infant spontaneous movement videos.
                                    <br>2. Compared STAM's and SMNN's performance in classify sequences.
                                    <br>3. Modifed the structure of STAM to accommodate small datasets.
                                    <br>4. Pre-process and post-process: Stabilized videos and eliminated the impact of infant relative camera position, distance, and angle on action sequences.
                                    
                                </p>
                            </li>
                             <li>
                                <i class="fa fa-bars" aria-hidden="true"></i>
                                <b>Result & Benefit:</b> Develop a method suitable for small datasets to identify infant developmental disorders.
                             </li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span>Improving Object Detection for Infrared Images Using YOLO</span>
                            <time>2022.10 - 2022.12</time>
                        </h3>
                        <p>University & Supervisor: KTH Royal Institute of Technology, Meng Zhang</p>
                        <ul class="info-content">
                            <li>
                                <i class="fa fa-paper-plane-o" aria-hidden="true"></i>
                                <b>Purpose:</b> Change YOLOv5 network to improve its recognition performance on infrared images.
                            </li>
                            <li>
                                <i class="fa fa-file-text-o" aria-hidden="true"></i>
                                <b>Contribution:</b><br />
                                <p>
                                    1. Added P2 layer and ASPP between the backbone and the head to detect smaller objects.
                                    <br>2. Used dialation and subpixel in Conv layer in Yolo to extract richer information while reduce computational burden.
                                    <br>3. Added attention mechanisms such as SE, CBAM and SKA after each C3, and between backbone and head.
                                    <br>4. Pretrained YOLO with masked autoencoder to better learn image features.
                                    
                                </p>
                            </li>
                             <li>
                                <i class="fa fa-bars" aria-hidden="true"></i>
                                <b>Result & Benefit:</b> For FLIR dataset mAP score increased from 0.426 to 0.473 by adding P2 and ASPP. For KAIST dataset  mAP score increased from 0.208 to 0.213 by adding attention layer after each C3.
                             </li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span>NLP and Machine Learning in Review Text</span>
                            <time>2021.1 - 2021.2</time>
                        </h3>
                        <p>University & Supervisor: North Carolina State University, Edward F. Gehringer</p>
                        <ul class="info-content">
                            <li>
                                <i class="fa fa-paper-plane-o" aria-hidden="true"></i>
                                <b>Purpose:</b> Summarize text by deep learning method to increase grading efficiency.
                            </li>
                            <li>
                                <i class="fa fa-file-text-o" aria-hidden="true"></i>
                                <b>Contribution:</b><br />
                                <p>
                                    1. Designed a LSTM model for text summarization.
                                    <br>2. Compared performances of different machine learning text summarization models such as PEGASUS, BART, T5 and our model
                                    
                                </p>
                            </li>
                             <li>
                                <i class="fa fa-bars" aria-hidden="true"></i>
                                <b>Result & Benefit:</b> Utilized machine learning transformers to compress the raw comments to reasonable shorter ones and significantly saved instructors’ time and effort.
                             </li>
                        </ul>
                    </li>
                </ul>
            </section>


            <!-- 工作经历 -->

            <section class="project info-unit">
                <h2>
                    <i class="fa fa-paper-plane" aria-hidden="true"></i>Work Experience</h2>
                <hr />
                <ul>
                    <li>
                        <h3>
                            <span>Ongoing: Teaching Assistant in KTH Royal Institute of Technology</span>
                            <time>2023.10 - Current</time>
                        </h3>
                        <p>Participating as a TA of 'Image Analysis and Computer Visions'</p>
                        <ul class="info-content">
                            <li>Help students with labs' help sessions and grade in presentation sessions.</li>
                            <li>
                                Discuss the grading procedure for each respective lab.
                            </li>
                        </ul>
                    </li>
                    <li>
                        <h3>
                            <span>Ongoing: Research Intern in Karolinska Institutet</span>
                            <time>2023.10 - Current</time>
                        </h3>
                        <p></p>
                        <ul class="info-content">
                            <li>Planning to design a multimodal deep learning model for early detection of infant diseases.</li>
                        </ul>
                    </li>
                     <li>
                        <h3>
                            <span>Research Assistant at Artificial Intelligence & Translational Theranostics Lab, Bern University</span>
                            <time>2022.7 - 2023.10</time>
                        </h3>
                        <p>Hold the Ultra-low Dose PET Imaging Challenge for 2022 & 2023.</p>
                        <ul class="info-content">
                            <li>Evaluated recovered PET data submitted by the participating groups.</li>
                            <li>
                                Summarized the algorithms (3D-AEGA, Unet++, HRNet3D and so on) submitted by the participating groups. Analyzed and discussed the results of different networks and strategies.
                            </li>
                            <li>
                                Preprocessed the PET dataset required for competition and visualization of the challenge results.
                            </li>
                            <li>
                                <b>Challenge Website:</b> Description of Ultra-low Dose PET Imaging Challenge
                                <span class="link">
                                <a href="https://ultra-low-dose-pet.grand-challenge.org/Description/" target="_blank">Link</a>
                            </span>
                            </li>
                        </ul>
                    </li>
                     <li>
                        <h3>
                            <span>Summer Intern at Wuhan National Laboratory for Optoelectronics (WNLO)</span>
                            <time>2021.5 - 2021.9</time>
                        </h3>
                        <p>Data Statistics and Analysis of Living Optical Imaging Cells</p>
                        <ul class="info-content">
                            <li>Designed an automated method that combines image registration and Unet to measure fluorescence intensity in images.</li>
                            <li>
                                Preprocessed and statistically analyzed optical images.
                            </li>
                        </ul>
                    </li>

                </ul>
            </section>

            <!-- 专业能力 -->
            <section class="work info-unit">
                <h2>
                    <i class="fa fa-pencil" aria-hidden="true"></i>Skills and Competences</h2>
                <hr />
                <p> <b>Knowledge:</b> Medical Image Reconstruct; Action Recognition; Computational Neuroscience; Biomedical Sensor; Anatomy and Physiology.
                </p>
                <p>
                    <b>Frameworks:</b> Tensorflow, Pytorch
                </p>
                <p>
                    <b>Programming:</b> Python, Matlab, C++, html
                </p>
            </section>


            



        </section>
    </article>


    <footer class="footer">
        <p> <b>Thank you for reading my resume. I'm looking forward to work with you.</b> </p>
    </footer>

    <!-- 侧栏 -->
    <aside>
        <ul>
            <li>
                <a href="https://github.com/hackhu2019" target="_blank">Github</a>
            </li>
            <li>
                <a href="https://blog.csdn.net/qq_38288847" target="_blank">Blog</a>
            </li>
        </ul>
    </aside>

    <script src="./assets/js/index.js" type="text/javascript"></script>

</body>

</html>
